---
title: "TI_Simulation"
author: "Petra Borovska"
date: "1 července 2020"
output: 
        html_document:
        toc: true
        toc_float: true
        toc_depth: 2
        number_sections: true
        theme: flatly
---


### Cleaning

clean environment and console

```{r clean_console}
cat("\014")
```



```{r clean_envir}
rm(list = ls())
```



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# ## install packages
# install.packages("knitr")
# install.packages("devtools")
# install.packages("here")
# install.packages("tidyverse")
# devtools::install_github("hadley/emo")
# install.packages("viridis")
# devtools::install_github("mikabr/ggpirate")
# install.packages("afex")
# install.packages("bootES")
# 


# install.packages("ez")

## load packages
library(knitr)
library(devtools)
library(here)
library(tidyverse)
library(emo)
library(viridis)
library(ggpirate)
library(afex)
library(emmeans)
library(multcomp)
library(bootES)
library(broom)
library(ez)

```

```{r dir}

getwd()

```




## Playing with the simulation from Hepach

```{r mySim}

## Our model parameters
# id = subjNr
# dv = prop
# within = pairType
# between = cond
# type = 3


# 0 = wake
# 1 = sleep

# 0 = prem
# 1 = inference


set.seed(1234)                  ## initial seed, not important for interpretation
intercept = 0.5                 ## knowing that dv is between 0 and 1
beta.condition = 0.5              ## knowing that dv is between 0 and 1
nr.simulations = 200
residual.variation = 1          ## used as sd for simulating random numbers with mean 0
alpha = 0.05
sample.sim.size = 240
sample.mod.size = 80            ## actual sample size entering the model
sample.size.Y = 2000

# Store p-values here:                  ## rep is just making a space in the variable
p.vals=rep(x=0, time= nr.simulations)   ## creating empty variable for p values with size of number of simulations
c.d=rep(x=0, time= nr.simulations)      ## creating empty variable for standardized dependent variable set with size of number of simulations



c = c(1,1,0,0)

subj = rep(1:60, each=4)
subj = as.integer(subj)

cond = rep(0:1, each=2, len=240)
cond = as.factor(cond)

pairType = rep(0:1, 120)
pairType = as.factor(pairType)

## columns for simulated df
subj = rep(1:60, each=4)
cond = rep(0:1, each=2, len=240)
pairType = rep(0:1, 120)


for(a in 1:nr.simulations){
        
	# Sample condition and gender.
	# condition.sample = sample(c(0,1), size= sample.sim.size, replace=T)
	# condition.sample_pair = sample(c(0,1), size= sample.sim.size, replace=T)
        
        condition.sample = cond
        condition.sample_pair = pairType

	
	# Simulate data. 
        
        Y = rnorm(n= sample.size.Y, sd=residual.variation, mean=0)
        
	Y = round(Y,2)                                      ## rounding number to non decimal
	
	Y = as.data.frame(Y)
	Y = Y[Y$Y >= 0 & Y$Y <=1, ]
	Y = Y[1:240]
	Y = as.numeric(Y)
        
        
	Y = intercept + beta.condition* condition.sample * condition.sample_pair + Y
	
# 
	condition.sample = as.factor(condition.sample)
	condition.sample_pair = as.factor(condition.sample_pair)
	subj = as.integer(subj)


	sim.data = data.frame(cbind(subj, condition.sample, condition.sample_pair, Y))
	                        ## creating df with two columns - condition
	                                                    ## and y as dv
	names(sim.data) <- c("subj", "cond", "pairType", "Y")


	# (2) Running the model
	# Select sample
	sim.data.sub = sim.data[1:sample.mod.size, ]  ## selecting smaller                                                                                       data set given above as                                                                                    sample.mod.size



#
	full.model_tidy = aov_ez(
        data = sim.data.sub,
        id = "subj",
        dv = "Y",
        within = c("pairType", "cond"),
        type = 3
        )
        
	# full.model.sum = summary(full.model_tidy)                   ## getting summary
	
	p.vals[a] <- full.model_tidy$anova_table[3,6]         ## locating p value from the summary table
	
}



# Look at the result.
sum(p.vals<0.05)/nr.simulations       ## get a proportion of significant values


sum_p = sum(p.vals<0.05)

```



## Jacob simulation

### Simulate one data frame

This would have to be done for each simulation


```{r get some data}

# some params
n_subs <- 40
n_groups <- 2
conds <- c("premise", "inference")
n_conds <- length(conds)

# start with subject variable and convert it to factor
dat <- tibble(subject = rep(1:n_subs, each = n_conds))

# add more columns
dat <- dat %>% add_column(
  # add group variable
  group = rep(c("wake", "sleep"), each = (n_subs/n_groups)*n_conds),
  # add condition variable (trial type)
  cond = rep(conds, n_subs)
  )

# convert to factor
dat<- dat %>% mutate(
  subject = as.factor(subject),
  group = as.factor(group),
  cond = as.factor(cond)
)

# add percent correct 
dat <- dat %>% add_column(
  # for now the simplest case: uniform between 0 and 1
  perc_corr = runif(n_subs*n_conds)
)


```

## Run the analysis

Start with the simplest case: a mixed ANOVA with 2 factors:

- group (between subjects)
- conditions (within subject)

```{r}

fit <- aov_ez(
  "subject",
  "perc_corr",
  data = dat,
  between=c("group"),
  within=c("cond"))

fit
```



### My version with measure around 0.75

#### Variables

DV = proportion of correct responses
IV between = condition: sleep and wake
IV within = pair type: premise and inference

IV extended = pair type: premise, anchor, oneDegree, twoDegree

IV extended smaller = pair type: oneDegree, twoDegree


### Prototype to insert later in the loop

```{r prepare_data}

## parameters
nuSubj = 20
nrCond_bet = 2
nrCond_wth = 2
cond_bet = c("wake", "sleep")
cond_wth = c("premise", "inference")


## empty tibble
myData = tibble()

## subject
subject = rep(1:nuSubj, times = nrCond_bet)
## create IV within
pair = rep(cond_wth, times = nuSubj)
## create IV between
cond = rep(cond_bet, each = nrCond_bet, times = nuSubj/nrCond_bet)

## create empty tibble (to reset previous)
myData = tibble(condition = cond, pairType = pair)

## arrange to pair type and condition so the dv is added appropriately
myData =
        myData %>%
        arrange(
                pairType,
                condition
        )
## creating the tresholds for each group - vary then
w_prem = 0.90
w_inf = 0.55
s_prem = 0.90
s_inf = 0.75


## creating a sample of each treshold
w_prem_sample = runif(nuSubj/nrCond_bet, min=w_prem, max=1)
w_inf_sample = runif(nuSubj/nrCond_bet, min=w_inf, max=0.65)
s_prem_sample = runif(nuSubj/nrCond_bet, min=s_prem, max=1)
s_inf_sample = runif(nuSubj/nrCond_bet, min=s_inf, max=1)

## get means
# mean(w_prem_sample)
# mean(w_inf_sample)
# mean(s_prem_sample)
# mean(s_inf_sample)


## performance bind - the order is dependent on the arrangment before
perf = c(s_inf_sample, w_inf_sample, s_prem_sample, w_prem_sample)


## add performance
myData <- 
        myData %>%
        add_column(
                perf = perf, .after = "pairType"
        ) 

# convert to factor
myData <- 
        myData %>%
        add_column(
                subject = subject, .before = "condition"
        ) %>%
        mutate(
                subject = as.factor(subject),
                pairType = as.factor(pairType),
                condition = as.factor(condition)
                )


```

### Model for simple 2 x 2 anova


```{r run_modelSimple}
model <- aov_ez(
        "subject",
        "perf",
        data = myData,
        between = c("condition"),
        within = c("pairType")
        
)

model$anova_table
model$anova_table[3, "Pr(>F)"]

```



### Simulation loop

We can vary number of participants, means of the contrast groups,
and number of simulations.



```{r loop_sim, message=FALSE, error=FALSE}


## parameters
nuSubj = 40
nrCond_bet = 2
nrCond_wth = 2
cond_bet = c("wake", "sleep")
cond_wth = c("premise", "inference")
myData = tibble()

## creating the tresholds for each group - vary then
w_prem = 0.90
w_inf = 0.55
s_prem = 0.90
s_inf = 0.75

## loop paramaters
nr_sim = 100
p_value = 0
set.seed(123)


for(i in 1:nr_sim){

        
        ## subject
        subject = rep(1:nuSubj, times = nrCond_bet)
        ## create IV within
        pair = rep(cond_wth, times = nuSubj)
        ## create IV between
        cond = rep(cond_bet, each = nrCond_bet, times = nuSubj/nrCond_bet)
        
        ## create empty tibble (to reset previous)
        myData = tibble(condition = cond, pairType = pair)
        
        ## arrange to pair type and condition so the dv is added appropriately
        myData =
                myData %>%
                arrange(
                        pairType,
                        condition
                )
        
        ## creating a sample of each treshold
        w_prem_sample = runif(nuSubj/nrCond_bet, min=w_prem, max=1)
        w_inf_sample = runif(nuSubj/nrCond_bet, min=w_inf, max=1)
        s_prem_sample = runif(nuSubj/nrCond_bet, min=s_prem, max=1)
        s_inf_sample = runif(nuSubj/nrCond_bet, min=s_inf, max=1)
        
        ## performance bind - the order is dependent on the arrangment before
        perf = c(s_inf_sample, w_inf_sample, s_prem_sample, w_prem_sample)
        
        ## add performance
        myData <- 
                myData %>%
                add_column(
                        perf = perf, .after = "pairType"
                ) 
        
        # convert to factor
        myData <- 
                myData %>%
                add_column(
                        subject = subject, .before = "condition"
                ) %>%
                mutate(
                        subject = as.factor(subject),
                        pairType = as.factor(pairType),
                        condition = as.factor(condition)
                        )
        
        model <- aov_ez(
                "subject",
                "perf",
                data = myData,
                between = c("condition"),
                within = c("pairType")
        )
        
        p_value[i] = model$anova_table[3, "Pr(>F)"]

}

## proportion of getting p values from the anova
sum(p_value<0.05)/nr_sim



```



### Processing Pilot Data

```{r load_clean_data}

## loading clean data in long format
tr_tot_trim = read.csv(here("outputFiles_R", "tr_tot_trim.csv"))
ts_tot_trim = read.csv(here("outputFiles_R", "ts_tot_trim.csv"))

```


### Subsetting for different purposes

1. Dataset for simple model, 2x2: pairType and condition


```{r subset_forSimpleModel}


## get rid of irrelevant columns
ts_first =
        ts_tot_trim %>%
        dplyr::select(
                key_resp_test.corr, pairType, participant, condition
        )

## change to factors
ts_first = 
        ts_first %>%
        mutate(
                pairType = as_factor(pairType),
                participant = as_factor(participant),
                condition = as_factor(condition)
                )

## calculate proportions
ts_first = 
        ts_first %>%
        group_by(
                pairType,
                condition,
                participant

        ) %>% 
        summarise(
                tot = sum(key_resp_test.corr),
                n = n()
        ) %>%
        mutate(
                prop = tot/n
        ) %>%
        ungroup()

## drop not useful columns
ts_first =
        ts_first %>%
        dplyr::select(
                pairType, condition, participant, prop
        ) %>%
        filter(
                pairType == "premise" | pairType == "oneDegree" | pairType == "twoDegree"
        )

## colapse inference 

ts_first_collapse =
        ts_first %>%
        filter(
                pairType == "oneDegree" | pairType == "twoDegree"
        ) %>%
        group_by(
                participant,
                condition
        ) %>%
        summarise(
                prop = mean(prop)
        )
ts_first_collapse =
        ts_first_collapse %>%
        add_column(
                pairType = rep("inference", times=length(ts_first_collapse$participant))
        )


## add the inference prop to premise
ts_first_all =
        ts_first %>%
        filter(
                pairType == "premise"
        )
ts_first_all = 
        full_join(
                ts_first_all, ts_first_collapse
        )



## selecting participants, so it's balanced in conditions
ts_first_selected =
        ts_first_all %>%
        filter(
                participant == "7" | participant == "8" | participant == "18" |
                        participant == "19" | participant == "17" | participant == "15" |
                        participant == "20" | participant == "21"
        )

```


### Looking at pilot data - anova within/between


```{r model_filot}

model_pilot <- aov_ez(
        "participant",
        "prop",
        data = ts_first_selected,
        between = c("condition"),
        within = c("pairType")
)

model_pilot

```


Calculating sd for pilot data


```{r sd_pilot}

## getting mean and sd based on pair type
desc_stat_pair =
        ts_first_selected %>%
        group_by(
                pairType
        ) %>%
        summarise(
                mean_pair = mean(prop),
                sd_pair =  sd(prop)
        ) %>%
        ungroup()



## getting mean and sd based on condition

desc_stat_cond =
        ts_first_selected %>%
        group_by(
                condition
        ) %>%
        summarise(
                mean_cond = mean(prop),
                sd_cond =  sd(prop)
        ) %>%
        ungroup()

desc_stat_both =
        ts_first_selected %>%
        group_by(
                condition, 
                pairType
        ) %>%
        summarise(
                mean = mean(prop),
                sd =  sd(prop)
        ) %>%
        ungroup()
        


```



Plot selected pilot data 
4 sleep, 4 wake


```{r plot_pilot}

pilot_Plot = ggplot(data = ts_first_selected, aes(x=pairType, y=prop))
pilot_Plot + 
        stat_summary(geom = "bar", position="dodge", colour = 'black',
                     aes(fill=condition)) +
        scale_fill_manual(values = c("lightblue", "grey")) + 
        labs(title='Mean proportion in condition by pairType', x='pair type',
             y='proportions', fill='condition') +
        coord_cartesian(ylim=c(0.5, 1))


```

Simulation to see whether it's better to sample out of sample, 
or just directly generate just 10 numbers per group.


```{r sampling_decision}

## check how often I get desired mean with apporach of recoding
mean_withoutSample = 0
for(j in 1:50){

        w_inf = rnorm(10, desc_stat_both$mean[1], desc_stat_both$sd[1])
        
        for(i in 1:length(w_inf)){
                #print(w_inf[i])
                if(w_inf[i] >= 1){
                        w_inf[i] = 1
                } else if(w_inf[i] <= 0){
                        w_inf[i] = 0
                }
        }
        
        mean_withoutSample[j] = mean(w_inf)
}

mean(mean_withoutSample)


## if I sample out of it

mean_withoutSample = 0
for(j in 1:50){

        w_inf_big = rnorm(100, desc_stat_both$mean[1], desc_stat_both$sd[1])
        w_inf = sample(w_inf_big, 10)
        
        for(i in 1:length(w_inf)){
                #print(w_inf[i])
                if(w_inf[i] >= 1){
                        w_inf[i] = 1
                } else if(w_inf[i] <= 0){
                        w_inf[i] = 0
                }
        }
        
        mean_withoutSample[j] = mean(w_inf)
}

mean(mean_withoutSample)


## conclusion 
## it does not matter much

```



```{r random_sample approach1}

w_inf = rnorm(100, desc_stat_both$mean[1], desc_stat_both$sd[1])
w_inf_range = sample(w_inf[w_inf >=0 & w_inf <=1], 10)


w_prem = rnorm(100, desc_stat_both$mean[2], desc_stat_both$sd[2])
w_prem_range = sample(w_prem[w_prem >=0 & w_prem <=1], 10)


s_inf = rnorm(100, desc_stat_both$mean[3], desc_stat_both$sd[3])
s_inf_range = sample(s_inf[s_inf >=0 & s_inf <=1], 10)


s_prem = rnorm(100, desc_stat_both$mean[4], desc_stat_both$sd[4])
s_prem_range = sample(s_prem[s_prem >=0 & s_prem <=1], 10)


```


Draw sample based on mean for appropriate group and 
sd which can be defined as - per group, or in total from pilot data. 

For loop recodes the values higher than 1 to 1, and below 0 to 0.
Mean is then not as inserted, but it's circulates around.


```{r random_sample approach2}
desc_stat_both


## random sample with mean and sd from pilot data in range 0 and 1

w_inf = rnorm(10, desc_stat_both$mean[1], desc_stat_both$sd[1])
for(i in 1:length(w_inf)){
        #print(w_inf[i])
        if(w_inf[i] >= 1){
                w_inf[i] = 1
        } else if(w_inf[i] <= 0){
                w_inf[i] = 0
        }
}


w_prem = rnorm(10, desc_stat_both$mean[2], desc_stat_both$sd[2])
for(i in 1:length(w_prem)){
        #print(w_inf[i])
        if(w_prem[i] >= 1){
                w_prem[i] = 1
        } else if(w_inf[i] <= 0){
                w_prem[i] = 0
        }
}


s_inf = rnorm(10, desc_stat_both$mean[3], desc_stat_both$sd[3])
for(i in 1:length(s_inf)){
        #print(w_inf[i])
        if(s_inf[i] >= 1){
                s_inf[i] = 1
        } else if(w_inf[i] <= 0){
                s_inf[i] = 0
        }
}


s_prem = rnorm(10, desc_stat_both$mean[4], desc_stat_both$sd[4])
for(i in 1:length(s_prem)){
        #print(w_inf[i])
        if(s_prem[i] >= 1){
                s_prem[i] = 1
        } else if(s_prem[i] <= 0){
                s_prem[i] = 0
        }
}


```


### Power analysis with more sensitive data


```{r loop_moreSensitiveData, message=FALSE, error=FALSE}


## means and sd

## means from pilot data
# desc_stat_both[1]   ## mean of w_inf
# desc_stat_both[2]   ## mean of w_prem
# desc_stat_both[3]   ## mean of s_inf
# desc_stat_both[4]   ## mean of s_prem

## artificial means of expected outcome 
# w_prem = 0.90
# w_inf = 0.55
# s_prem = 0.90
# s_inf = 0.75

## sd - either use per group or total sd for the whole pilot data


## sd per group
# desc_stat_both$sd[1]  ## mean of w_inf
# desc_stat_both$sd[2]  ## mean of w_prem
# desc_stat_both$sd[3]  ## mean of s_inf
# desc_stat_both$sd[4]  ## mean of s_prem

## sd total
sd_tot =
        ts_first_all %>%
        summarise(
                sd_tot = sd(prop)
        ) %>%
        pull()

## creating the tresholds for each group - vary then
w_prem_th = 0.98
w_inf_th = 0.55
s_prem_th = 0.98
s_inf_th = 0.85

## double checking means
mean_w_prem = 0
mean_w_inf = 0
mean_s_prem = 0
mean_s_inf = 0


## loop paramaters
nr_sim = 200
p_value = 0
set.seed(123)

## parameters
nuSubj = 52
nrCond_bet = 2
nrCond_wth = 2
cond_bet = c("wake", "sleep")
cond_wth = c("premise", "inference")
myData = tibble()

for(j in 1:nr_sim){

        
        ## subject
        subject = rep(1:nuSubj, times = nrCond_bet)
        ## create IV within
        pair = rep(cond_wth, times = nuSubj)
        ## create IV between
        cond = rep(cond_bet, each = nrCond_bet, times = nuSubj/nrCond_bet)
        
        ## create empty tibble (to reset previous)
        myData = tibble(condition = cond, pairType = pair)
        
        ## arrange to pair type and condition so the dv is added appropriately
        myData =
                myData %>%
                arrange(
                        pairType,
                        condition
                )
        
        ## creating a sample of each treshold
        ## random sample with mean and sd from pilot data in range 0 and 1
        w_inf = rnorm(nuSubj/nrCond_bet, w_inf_th, sd_tot)
        for(a in 1:length(w_inf)){
                #print(w_inf[i])
                if(w_inf[a] >= 1){
                        w_inf[a] = 1
                } else if(w_inf[a] <= 0){
                        w_inf[a] = 0
                }
        }
        
        
        w_prem = rnorm(nuSubj/nrCond_bet, w_prem_th, sd_tot)
        for(b in 1:length(w_prem)){
                #print(w_inf[i])
                if(w_prem[b] >= 1){
                        w_prem[b] = 1
                } else if(w_inf[b] <= 0){
                        w_prem[b] = 0
                }
        }
        
        
        s_inf = rnorm(nuSubj/nrCond_bet, s_inf_th, sd_tot)
        for(c in 1:length(s_inf)){
                #print(w_inf[i])
                if(s_inf[c] >= 1){
                        s_inf[c] = 1
                } else if(w_inf[c] <= 0){
                        s_inf[c] = 0
                }
        }
        
        
        s_prem = rnorm(nuSubj/nrCond_bet, s_prem_th, sd_tot)
        for(d in 1:length(s_prem)){
                #print(w_inf[i])
                if(s_prem[d] >= 1){
                        s_prem[d] = 1
                } else if(s_prem[d] <= 0){
                        s_prem[d] = 0
                }
        }

        
        ## performance bind - the order is dependent on the arrangment before
        perf = c(s_inf, w_inf, s_prem, w_prem)
        
        ## add performance
        myData <- 
                myData %>%
                add_column(
                        perf = perf, .after = "pairType"
                ) 
        
        # convert to factor
        myData <- 
                myData %>%
                add_column(
                        subject = subject, .before = "condition"
                ) %>%
                mutate(
                        subject = as.factor(subject),
                        pairType = as.factor(pairType),
                        condition = as.factor(condition)
                        )
        
        model <- aov_ez(
                "subject",
                "perf",
                data = myData,
                between = c("condition"),
                within = c("pairType")
        )
        
        p_value[j] = model$anova_table[3, "Pr(>F)"]
        mean_w_prem[j] = mean(w_prem)
        mean_w_inf[j] = mean(w_inf)
        mean_s_prem[j] = mean(s_prem)
        mean_s_inf[j] = mean(s_inf)
                

}

## proportion of getting p values from the anova
propP = sum(p_value<0.05)/nr_sim

## which means where considered in the model - double check
meanW_prem = mean(mean_w_prem)
meanW_inf = mean(mean_w_inf)
meanS_prem = mean(mean_s_prem)
meanS_inf = mean(mean_s_inf)


## results
# highEffs_40Subj = rbind(propP, meanW_prem, meanW_inf, meanS_prem, meanS_inf)
# highEffs_40Subj

# highEffs_52Subj = rbind(propP, meanW_prem, meanW_inf, meanS_prem, meanS_inf)
# highEffs_52Subj

# lowEffs_40Subj = rbind(propP, meanW_prem, meanW_inf, meanS_prem, meanS_inf)
# lowEffs_40Subj


```



